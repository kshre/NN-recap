{
 "metadata": {
  "name": "",
  "signature": "sha256:41502ad0d55fa47f976248a9ec24ad94cee8b2a088b0fe1456bb2889e7a46d03"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "from drawnow import drawnow\n",
      "%pylab inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "WARNING: pylab import has clobbered these variables: ['tanh']\n",
        "`%matplotlib` prevents importing * from pylab and numpy\n"
       ]
      }
     ],
     "prompt_number": 1341
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from numpy import genfromtxt\n",
      "nifty_data = genfromtxt('data.csv', delimiter='\",\"')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1342
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cleaner_data = nifty_data[1:, [1, 2, 3, 4]]\n",
      "# open, high, low, close"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1343
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "shape(cleaner_data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1344,
       "text": [
        "(248, 4)"
       ]
      }
     ],
     "prompt_number": 1344
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy import stats\n",
      "cleaner_data = stats.zscore(cleaner_data)\n",
      "# rescale to x-mu/sigma"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1345
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x = cleaner_data # cleaned up input\n",
      "y = cleaner_data[:, [3]] # ground truth"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1346
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# for time series, either use x\n",
      "# or make a new input array x_time, each row has five time steps\n",
      "# where x_time[0] = [x[0], x[1], x[2], x[3], x[4]]\n",
      "# and so on"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1347
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x_time = np.array([x[0], x[1], x[2], x[3], x[4]]).flatten()\n",
      "for i in xrange(1, 244):\n",
      "    x_time = np.vstack((x_time, np.array([x[i+0], x[i+1], x[i+2], x[i+3], x[i+4]]).flatten()))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1348
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "shape(x_time)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1349,
       "text": [
        "(244, 20)"
       ]
      }
     ],
     "prompt_number": 1349
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "shape(y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1350,
       "text": [
        "(248, 1)"
       ]
      }
     ],
     "prompt_number": 1350
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x_time = x_time[0:243] # chop of the last input in the time series\n",
      "# data limit reached"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1351
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_time = y[5:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1352
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_time = (y_time + 1) / 2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1353
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#y_time = nifty_data[6:, [4]] / max(nifty_data[6:, [4]])\n",
      "y_time[100:110]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1354,
       "text": [
        "array([[ 0.25362194],\n",
        "       [ 0.15210177],\n",
        "       [ 0.12080392],\n",
        "       [ 0.26765201],\n",
        "       [ 0.03871001],\n",
        "       [ 0.06396414],\n",
        "       [ 0.10857257],\n",
        "       [ 0.15663457],\n",
        "       [ 0.22030951],\n",
        "       [ 0.33981695]])"
       ]
      }
     ],
     "prompt_number": 1354
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "shape(x_time), shape(y[5:])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1355,
       "text": [
        "((243, 20), (243, 1))"
       ]
      }
     ],
     "prompt_number": 1355
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "######################################################\n",
      "######################################################\n",
      "##### Input and Output ready to train neural net #####\n",
      "######################################################\n",
      "######################################################"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1356
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# number of neurons\n",
      "neuronsL1, neuronsL2 = (100,50)\n",
      "# learning rate\n",
      "alpha, dropout_percent, do_dropout = (0.03, 0.2, True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1357
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.random.seed(None)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1358
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# unipolar sigmoid\n",
      "def sigmoid(x, derivative):\n",
      "    sig_x = 1 / (1 + np.exp(-0.5 * x)) # compute sigmoid(x)\n",
      "    if (derivative == False):\n",
      "        return sig_x\n",
      "    if (derivative == True):\n",
      "        return sig_x * (1 - sig_x) # derivative of sigmoid(x)\n",
      "\n",
      "# tangent hyperbolic\n",
      "def tanh(x, derivative):\n",
      "    tanh_x = np.tanh(x)\n",
      "    if (derivative == False):\n",
      "        return tanh_x\n",
      "    if (derivative == True):\n",
      "        return 1 - tanh_x ** 2\n",
      "\n",
      "# linear rectifier\n",
      "def relu(x, derivative):\n",
      "    if (derivative == False):\n",
      "        return x * (x > 0)\n",
      "    if (derivative == True):\n",
      "        return 1 * (x > 0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1359
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# vectorized sigmoid\n",
      "vsigmoid = np.vectorize(sigmoid)\n",
      "\n",
      "# vectorized tanh\n",
      "vtanh = np.vectorize(tanh)\n",
      "\n",
      "# vectorized relu\n",
      "vrelu = np.vectorize(relu)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1360
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# input to hidden layer 1 weights, column x corresponds to weights of xth neuron in the hidden layer \n",
      "w1 = 2 * np.random.rand(20, neuronsL1) - 1\n",
      "# hidden layer to hidden layer 2 weights\n",
      "w2 = 2 * np.random.rand(neuronsL1, neuronsL2) - 1\n",
      "# hidden to output layer weights\n",
      "w3 = 2 * np.random.rand(neuronsL2, 1) - 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1361
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# biases of hidden layer 1 neurons\n",
      "b1 = np.random.rand(1, neuronsL1)\n",
      "# baises of hidden layer 2 neurons\n",
      "b2 = np.random.rand(1, neuronsL2)\n",
      "# biases of output layer neuron\n",
      "b3 =  np.random.rand(1,1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1362
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# plot error versus iterations\n",
      "def makeFig():\n",
      "    plt.scatter(iterations,errors)\n",
      "\n",
      "plt.ion() # enable interactivity\n",
      "fig=plt.figure() # make a figure\n",
      "\n",
      "iterations=list()\n",
      "errors=list()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<matplotlib.figure.Figure at 0x7f32aeaf7850>"
       ]
      }
     ],
     "prompt_number": 1363
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in range(100):\n",
      "    # activations of hidden layer 1\n",
      "    l1 = vsigmoid(x_time.dot(w1) + b1, False)\n",
      "    if(do_dropout):\n",
      "        l1 *= np.random.binomial([np.ones((len(x_time),neuronsL1))],1-dropout_percent)[0] * (1.0/(1-dropout_percent))\n",
      "    # activations of hidden layer 2\n",
      "    l2 = vsigmoid(l1.dot(w2) + b2, False)\n",
      "    if(do_dropout):\n",
      "        l2 *= np.random.binomial([np.ones((len(l1),neuronsL2))],1-dropout_percent)[0] * (1.0/(1-dropout_percent))\n",
      "    # activations of the output layer\n",
      "    l3 = vsigmoid(l2.dot(w3) + b3, False)\n",
      "\n",
      "    delta_l3 = (y_time - l3) * vsigmoid(l2.dot(w3) + b3, True)\n",
      "    delta_l2 = delta_l3.dot(w3.T) * vsigmoid(l1.dot(w2) + b2, True)\n",
      "    delta_l1 = delta_l2.dot(w2.T) * vsigmoid(x_time.dot(w1) + b1, True)\n",
      "    \n",
      "    w1 += alpha * x_time.T.dot(delta_l1)\n",
      "    b1 += alpha * np.ones((1, 243)).dot(delta_l1)\n",
      "    \n",
      "    w2 += alpha * l1.T.dot(delta_l2)\n",
      "    b2 += alpha * np.ones((1, 243)).dot(delta_l2)\n",
      "    \n",
      "    w3 += alpha * l2.T.dot(delta_l3)\n",
      "    b3 += alpha * np.ones((1, 243)).dot(delta_l3)\n",
      "    \n",
      "    error = np.sqrt(np.mean(np.square(y_time - l3)))\n",
      "    \n",
      "    #if (len(errors) > 0 and error > errors[-1]):\n",
      "    #    break\n",
      "        \n",
      "    # record keeping for plot\n",
      "    errors.append(error)\n",
      "    iterations.append(i)\n",
      "    \n",
      "makeFig()\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEACAYAAAC57G0KAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npJCHtDuLZwAAAABJRU5ErkJggg==\n",
       "text": [
        "<matplotlib.figure.Figure at 0x7f32ae9a9ed0>"
       ]
      }
     ],
     "prompt_number": 1364
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# for debug, check shape of matrices involved\n",
      "print \"x_time.shape:\", x_time.shape\n",
      "print \"y_time.shape:\", y_time.shape\n",
      "print \"w1.shape:\", w1.shape\n",
      "print \"w2.shape:\", w2.shape\n",
      "print \"w3.shape:\", w3.shape\n",
      "print \"b1.shape:\", b1.shape\n",
      "print \"b2.shape:\", b2.shape\n",
      "print \"b3.shape:\", b3.shape\n",
      "print \"l1.shape:\", l1.shape\n",
      "print \"l2.shape:\", l2.shape\n",
      "print \"l3.shape:\", l3.shape\n",
      "print \"delta_l1.shape:\", delta_l1.shape\n",
      "print \"delta_l2.shape:\", delta_l2.shape\n",
      "print \"delta_l3.shape:\", delta_l3.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "x_time.shape: (243, 20)\n",
        "y_time.shape: (243, 1)\n",
        "w1.shape: (20, 100)\n",
        "w2.shape: (100, 50)\n",
        "w3.shape: (50, 1)\n",
        "b1.shape: (1, 100)\n",
        "b2.shape: (1, 50)\n",
        "b3.shape: (1, 1)\n",
        "l1.shape: (243, 100)\n",
        "l2.shape: (243, 50)\n",
        "l3.shape: (243, 1)\n",
        "delta_l1.shape: (243, 100)\n",
        "delta_l2.shape: (243, 50)\n",
        "delta_l3.shape: (243, 1)\n"
       ]
      }
     ],
     "prompt_number": 1365
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "##################################################\n",
      "################ TEST TIME #######################\n",
      "##################################################"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1366
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from numpy import genfromtxt\n",
      "nifty_test = genfromtxt('test.csv', delimiter='\",\"')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1367
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cleaner_test = nifty_test[1:, [1, 2, 3, 4]]\n",
      "shape(cleaner_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1368,
       "text": [
        "(18, 4)"
       ]
      }
     ],
     "prompt_number": 1368
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy import stats\n",
      "cleaner_test = stats.zscore(cleaner_test)\n",
      "xt = cleaner_test[:-1]\n",
      "yt = (cleaner_test[5:, [3]] + 1)/2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1369
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x_test_time = np.array([xt[0], xt[1], xt[2], xt[3], xt[4]]).flatten()\n",
      "for i in xrange(1, 13):\n",
      "    x_test_time = np.vstack((x_test_time, np.array([xt[i+0], xt[i+1], xt[i+2], xt[i+3], xt[i+4]]).flatten()))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1370
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "shape(xt), shape(yt), shape(x_test_time)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1371,
       "text": [
        "((17, 4), (13, 1), (13, 20))"
       ]
      }
     ],
     "prompt_number": 1371
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# activations of hidden layer 1\n",
      "l1 = vsigmoid(x_test_time.dot(w1) + b1, False)\n",
      "# activations of hidden layer 2\n",
      "l2 = vsigmoid(l1.dot(w2) + b2, False)\n",
      "    # activations of the output layer\n",
      "l3 = vsigmoid(l2.dot(w3) + b3, False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1372
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "error = np.sqrt(np.mean(np.square(yt - l3)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1373
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "error # test error"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1374,
       "text": [
        "0.1753618139706952"
       ]
      }
     ],
     "prompt_number": 1374
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "errors"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1375,
       "text": [
        "[0.64257172681659835,\n",
        " 0.44666377429246557,\n",
        " 0.53213566109124355,\n",
        " 0.46963963737714104,\n",
        " 0.35765767647749369,\n",
        " 0.26469447529185791,\n",
        " 0.25441745247837538,\n",
        " 0.26231327990162046,\n",
        " 0.25201129125828103,\n",
        " 0.24253938027578736,\n",
        " 0.25154553546347003,\n",
        " 0.25501742833082158,\n",
        " 0.25291952345675672,\n",
        " 0.24760875454166242,\n",
        " 0.24241042100617827,\n",
        " 0.24909475205986281,\n",
        " 0.25489730540922051,\n",
        " 0.24160151632766172,\n",
        " 0.24764236924399177,\n",
        " 0.24346173745412958,\n",
        " 0.2494402352999355,\n",
        " 0.24467557393538289,\n",
        " 0.23887332503004524,\n",
        " 0.24223927364841283,\n",
        " 0.24563942340024594,\n",
        " 0.24218932948355185,\n",
        " 0.25150182920133751,\n",
        " 0.25261058828730482,\n",
        " 0.2462138277647514,\n",
        " 0.24556731154408162,\n",
        " 0.22920399205495115,\n",
        " 0.24437917834671474,\n",
        " 0.23545901321018989,\n",
        " 0.23704002397674362,\n",
        " 0.24467008773330881,\n",
        " 0.24577541904552647,\n",
        " 0.24410827185156617,\n",
        " 0.23603513271509516,\n",
        " 0.24095811035293477,\n",
        " 0.23397463392728929,\n",
        " 0.23357532573452164,\n",
        " 0.23343376372687508,\n",
        " 0.2336886750090261,\n",
        " 0.24033265722547276,\n",
        " 0.2359938637853593,\n",
        " 0.23243386139875136,\n",
        " 0.22171838264584529,\n",
        " 0.23256968724965341,\n",
        " 0.23501260017296854,\n",
        " 0.23617950943929492,\n",
        " 0.23532376079611717,\n",
        " 0.24400496547366501,\n",
        " 0.23143060511865982,\n",
        " 0.23802063747496141,\n",
        " 0.2307219376643028,\n",
        " 0.22649317234630223,\n",
        " 0.23050258838693777,\n",
        " 0.22769488251368783,\n",
        " 0.23626501365159874,\n",
        " 0.2337163858802688,\n",
        " 0.22478045213798839,\n",
        " 0.23565600690370769,\n",
        " 0.22735553612675988,\n",
        " 0.23418273643191881,\n",
        " 0.22945392080177915,\n",
        " 0.24404375981113843,\n",
        " 0.2330287701142191,\n",
        " 0.22775892840119322,\n",
        " 0.2284587190380698,\n",
        " 0.22245820299380969,\n",
        " 0.23357729397461757,\n",
        " 0.23452966589065072,\n",
        " 0.24061845702124482,\n",
        " 0.22919212092684824,\n",
        " 0.23698389616222684,\n",
        " 0.23041381942497083,\n",
        " 0.22769020624974193,\n",
        " 0.22804442441721268,\n",
        " 0.22702550538769867,\n",
        " 0.22104199718920459,\n",
        " 0.23153493110675438,\n",
        " 0.22248425467170874,\n",
        " 0.23282255009762079,\n",
        " 0.2243618207167008,\n",
        " 0.22888875446462953,\n",
        " 0.23238160982889894,\n",
        " 0.22338232916141074,\n",
        " 0.23168946413596789,\n",
        " 0.22930314381146041,\n",
        " 0.23104645269147947,\n",
        " 0.21963256981146861,\n",
        " 0.22133047054174854,\n",
        " 0.22980543269697529,\n",
        " 0.22618028634003073,\n",
        " 0.21957714864860284,\n",
        " 0.22479993742810767,\n",
        " 0.22128371981937964,\n",
        " 0.22283158738110592,\n",
        " 0.22987505704619238,\n",
        " 0.23025157056826043]"
       ]
      }
     ],
     "prompt_number": 1375
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "[[yt.T], [l3.T]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1376,
       "text": [
        "[[array([[ 0.67184015,  0.56589194,  0.4145979 ,  0.56179527,  0.48946796,\n",
        "           0.20976469, -0.0354701 ,  0.20213642, -0.1532845 , -0.24510628,\n",
        "           0.16639656,  0.20510297,  0.20962343]])],\n",
        " [array([[ 0.84078165,  0.72145999,  0.47935687,  0.46903567,  0.34836736,\n",
        "           0.30101144,  0.27852701,  0.06460407,  0.05324993,  0.0267196 ,\n",
        "           0.02010183,  0.02537053,  0.07458314]])]]"
       ]
      }
     ],
     "prompt_number": 1376
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1376
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1376
    }
   ],
   "metadata": {}
  }
 ]
}